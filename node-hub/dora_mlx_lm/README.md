# Dora MLX-LM Node

## Overview

The `dora-mlx-lm` node integrates the [`mlx-lm`](https://github.com/ml-explore/mlx-lm) library to run large language models (LLMs) optimized for Apple Silicon on macOS. It processes a text prompt as input and generates a text response using a model such as `Qwen/Qwen2.5-7B-Instruct-MLX`.

## Installation

To use the `dora-mlx-lm` node, install the required dependencies:

```bash
pip install dora-rs-cli mlx-lm
```

## Usage

1. **Add the node to your DORA pipeline**:

   Include the `mlx_lm` node in your pipeline YAML file. Below is an example configuration:

   ```yaml
   nodes:
     - id: mlx_lm
       build: pip install mlx-lm
       path: dora-mlx-lm/dora_mlx_lm
       inputs:
         prompt: dora/input
       outputs:
         - text
       env:
         MODEL_PATH: Qwen/Qwen2.5-Omni-7B
   ```

2. **Run the pipeline**:

   Build and execute your pipeline using the DORA CLI:

   ```bash
   dora build your_pipeline.yml --uv
   dora run your_pipeline.yml --uv
   ```

## Inputs

- **prompt**: A text string to be processed by the LLM (e.g., "Write a short story about a robot").

## Outputs

- **text**: The text response generated by the LLM.

## License

This node is licensed under the [MIT License](https://opensource.org/licenses/MIT), consistent with the `mlx-lm` library.