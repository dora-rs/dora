[project]
name = "dora-qwen2-5-vl"
version = "0.3.10-rc1"
authors = [
    { name = "Haixuan Xavier Tao", email = "tao.xavier@outlook.com" },
    { name = "Enzo Le Van", email = "dev@enzo-le-van.fr" },
]
description = "Dora Node for VLM"
license = { text = "MIT" }
readme = "README.md"
requires-python = ">=3.9"

dependencies = [
    "dora-rs >= 0.3.6",
    "numpy < 2.0.0",
    "torch == 2.4.0",
    "torchvision >= 0.19",
    "torchaudio >= 2.1.0",
    "qwen-vl-utils >= 0.0.5",
    "opencv-python >= 4.1.1",
    "modelscope >= 1.18.1",
    "peft == 0.13.2",
    "accelerate>=1.3.0",
    "transformers",
    "setuptools>=65.0.0",
    # "flash-attn>=2.7.1; sys_platform != 'darwin'",
]

## Currently flash_attn is not supported as a pip install within uv.
# [[tool.uv.dependency-metadata]]
# name = "flash-attn"
# version = "2.7.1"
# requires = ["setuptools", "torch"]

# [tool.uv]
# no-build-isolation-package = ['flash-attn']


[dependency-groups]
dev = ["pytest >=8.1.1", "ruff >=0.9.1"]

[tool.uv.sources]
transformers = { git = "https://github.com/huggingface/transformers" }

[project.scripts]
dora-qwen2-5-vl = "dora_qwen2_5_vl.main:main"

[build-system]
requires = ["setuptools", "setuptools-scm"]
build-backend = "setuptools.build_meta"
