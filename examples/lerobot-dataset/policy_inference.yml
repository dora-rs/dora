nodes:
  # NOTE: The camera inputs should match the training setup
  - id: laptop_cam
    build: pip install opencv-video-capture
    path: opencv-video-capture
    inputs:
      tick: dora/timer/millis/33
    outputs:
      - image
    env:
      CAPTURE_PATH: "0"
      ENCODING: "rgb8"
      IMAGE_WIDTH: "640"
      IMAGE_HEIGHT: "480"

  - id: front_cam
    build: pip install opencv-video-capture
    path: opencv-video-capture
    inputs:
      tick: dora/timer/millis/33
    outputs:
      - image
    env:
      CAPTURE_PATH: "1" # ‚Üê UPDATE: Your external camera device
      ENCODING: "rgb8"
      IMAGE_WIDTH: "640"
      IMAGE_HEIGHT: "480"

  - id: so101_follower
    build: pip install -e ../../node-hub/dora-rustypot
    path: dora-rustypot
    inputs:
      tick: dora/timer/millis/10
      pose: policy_inference/robot_action
    outputs:
      - pose
    env:
      PORT: "/dev/ttyACM1" # UPDATE your robot port
      IDS: "1,2,3,4,5,6"

  - id: policy_inference
    build: pip install -e ../../node-hub/dora-policy-inference
    path: dora-policy-inference
    inputs:
      laptop: laptop_cam/image # the camera inputs should match the training setup
      front: front_cam/image
      robot_state: so101_follower/pose
    outputs:
      - robot_action
      - status
    env:
      MODEL_PATH: "./outputs/train/act_so101_test/checkpoints/last/pretrained_model/" # Path to your trained model
      TASK_DESCRIPTION: "Your task"
      ROBOT_TYPE: "so101_follower"
      CAMERA_NAMES: "front, laptop"
      INFERENCE_FPS: "30"

  # Visualization in rerun (optional)
  - id: plot
    build: pip install dora-rerun
    path: dora-rerun
    inputs:
      image_laptop: laptop_cam/image
      image_front: front_cam/image
      status: policy_inference/status
      jointstate_so101_new_calib: so101/pose
    env:
      so101_new_calib_urdf: "so_arm101_description"
      so101_new_calib_transform: "0. 0. 0. 1. 0. 0. 0."
