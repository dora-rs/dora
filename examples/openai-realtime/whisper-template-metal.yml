nodes:
  - id: NODE_ID
    path: dynamic
    inputs:
      audio: tts/audio
      text: stt/text
      speech_started: stt/speech_started
    outputs:
      - audio
      - text

  - id: dora-vad
    build: pip install -e ../../node-hub/dora-vad
    path: dora-vad
    inputs:
      audio:
        source: NODE_ID/audio
        queue_size: 1000000
    outputs:
      - audio
    env:
      MIN_SPEECH_DURATION_MS: 1000
      MIN_SILENCE_DURATION_MS: 1000
      THRESHOLD: 0.5

  - id: stt
    build: pip install -e ../../node-hub/dora-distil-whisper
    path: dora-distil-whisper
    inputs:
      audio: dora-vad/audio
    outputs:
      - text
      - word
      - speech_started

  - id: llm
    build: pip install -e ../../node-hub/dora-qwen
    path: dora-qwen
    inputs:
      text: stt/text
      text_to_audio: NODE_ID/text
    outputs:
      - text
    env:
      MODEL_NAME_OR_PATH: LLM_ID
      MODEL_FILE_PATTERN: "*[qQ]6_[kK].[gG][gG][uU][fF]"

  - id: tts
    build: pip install -e ../../node-hub/dora-kokoro-tts
    path: dora-kokoro-tts
    inputs:
      text: llm/text
    outputs:
      - audio
