nodes:
  - id: camera
    build: pip install -e ../../node-hub/opencv-video-capture
    path: opencv-video-capture
    inputs:
      tick: dora/timer/millis/100
    outputs:
      - image
    env:
      CAPTURE_PATH: "0"
      ENCODING: "rgb8"
      IMAGE_WIDTH: "640"
      IMAGE_HEIGHT: "480"

  - id: dora-qwenvl
    build: pip install -e ../../node-hub/dora-qwen2-5-vl
    path: dora-qwen2-5-vl
    inputs:
      image: camera/image
      text_1: dora/timer/millis/600
    outputs:
      - text
    env:
      DEFAULT_QUESTION: Output the bounding box of the eyes.
      IMAGE_RESIZE_RATIO: "0.5"
      # ACTIVATION_WORDS: grab pick give output take catch grabs picks gives output takes catches have
      #SYSTEM_PROMPT: You're a robot.

  - id: parse_bbox
    path: parse_bbox.py
    inputs:
      text: dora-qwenvl/text
    outputs:
      - bbox
    env:
      IMAGE_RESIZE_RATIO: "0.5"

  - id: tracker
    build: pip install -e ../../node-hub/dora-cotracker
    path: dora-cotracker
    inputs:
      image: camera/image
      boxes2d: parse_bbox/bbox
      # points_to_track: input/points_to_track    # uncomment this if using input node
    outputs:
      - tracked_image
      - points
    env:
      INTERACTIVE_MODE: false

  - id: plot
    build: pip install -e ../../node-hub/dora-rerun
    path: dora-rerun
    inputs:
      image: camera/image
      boxes2d: parse_bbox/bbox
      tracked_image: tracker/tracked_image

  # replace with your own node that outputs tracking points # uncomment if input via node
  # (e.g., YOLO detector, pose estimator, etc.)
  # - id: point_source
  #   build: pip install your-node  # Replace with your node's name
  #   path: your-point-source-node  # Replace with your node's path
  #   inputs:
  #     image: camera/image  # If your node needs image input
  #   outputs:
  #     - points_to_track    # Must output points in required format
